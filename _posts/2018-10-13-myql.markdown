---
layout:     post
title:      "个人已知的一些mysql查询性能优化"
subtitle:   ""
date:       2018-10-13 15:06:00
author:     "wantu"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - mysql
---

## 前言
[直奔正文](#build) 
到店达之后一开始接到了大量的导数的数据需求。还记得当时有一个需求是从数据库中拉每周的周报数据（财务）。
那个SQL写的非常的大而且开始的时候执行的速度很慢，差点就逼近了赤狐系统的临界执行时长。
因为一开始没想去用程序处理，也只是想把需求先搞出来。后面数据慢慢稳定。于是想把整个查询进行一些优化。
以下就是对于mysql查询性能优化的一些得。

<p id = "build"></p>
---

## 正文
先大致了解一下mysql的架构设计，mysql的逻辑架构分为三层。最上层大多数是基于网络的客户端。第二层是mysql的核心，mysql的核心服务功能都在此层，包括查询解析、分析、优化、缓存以及所有的内置函数。第三层则是存储引擎，引擎的职责是负责mysql中数据的存储和提取。各个引擎各有所长。服务器通过API与存储引擎进行通信。

查询慢可能的原因：
1、计算能力不足
2、设计表存在问题
3、建表时并没有建立高效的索引
4、SQL语句有提高的空间

解决办法：
1、如果数据体量比较大，mysql处理起来比较费力，可以考虑一些分布式计算框架。
2、如果一个表的基础数据量就已经够大了并且伴随较大的增量数据，可以考虑分表（按时间分等策略...）
3、索引，建立高性能的索引策略。（下面会细讲）
4、优化自己的SQL语句
5、基础数据预处理（中间表）

抛开数据量一上来就建索引就是耍流氓，因为mysql自身维护它也是需要消耗资源的，小表全表扫描简单粗暴又高效，超大型的表也不适合，索引的代价太高可用考虑分区技术。中到大型表，嘿嘿嘿，就是你了。
在innodb引擎使用的是B+tree索引,基于B-tree对索引列是顺序组织存储的缘故，所以很适合查找范围数据。
>创建高性能的索引：
1、查询中列不是独立的
独立的列指的是索引列不能是表达式的一部分，也不能是函数的参数。
select stu.name from stu where stu.id + 1 = 5.即使你在stu(显然id不会是主键哈)的id建了索引，并没有什么用。
2、前缀索引
有的时候需要索引很长的字符，这会导致索引变得大且慢，可以考虑索引开始的部分字符，此举可大大节约索引空间，从而提高索引效率，但也会导致另一索引选择性降低。（索引选择性 = 不重复的索引值/表的记录总数）
如何确定前缀索引的长度？
```sql
select count(1) as total,colu_name
from table_name t
group by colu_name
order by total desc 
limit 10;
```
可以得到某个列最频繁出现的前10个值，记录下来这10个值得范围作为标准。
```sql
select count(1) as total,left(colu_name,n) as pref
from table_name t
group by pref 
order by total desc
limit 10;
```
通过不断的调整上面n的值(前缀索引的长度)得到的范围值是接近标准中的最小的数值。
打个比方，当n=7时得到的范围值就已经很接近标准了，但是n=8的时候比7更接近但时范围差距很小，那么n=7较为合适。

创建前缀索引：
```sql
alter table table_name add key (colu_name(best_index_length)) 
//best_index_length最佳前缀索引长度
```

3、多列索引
如果在用explain查看SQL的执行计划中有发现有索引合并（type值为index_merge）的时候应该好好检查一下查询和表的结构。

a、当表中的多个单独的索引列做相交操作时(通常有多个AND条件)，通常需要一个包含所有相关列的所列索引而不是多个独立的单列索引。

4、选择合适的索引顺序
通常做法：将选择性高的列放到索引最前列

5、聚簇索引

6、删除未使用的索引和冗余的索引，这些索引是累赘，可以通过一些工具帮忙定位后删除。


>优化sql
```sql
select t.id,max(s.score) as 'this_is_my_best_student_score'
from teacher t,student s
where t.id = s.tid
group by t.id
having t.name like '%王%'
order by t.id desc
```
首先得知道整个SQL的执行顺序：
from -> where -> group by ->having ->select -> order by -> limit
from过程中如果使用的是自然连接那么会导致产生一张笛卡尔积的虚拟表，这样做是很蠢的。推荐使用外连接(会减少虚拟表的数据量)。
where 对虚拟表中的数据进行过滤，能放在这里的过滤别放having中进行过滤
group by
having 主要就是聚合函数结果进行过滤
select 只要自己要的数据！不需要的字段一个不要。
order by 
limit 

>基础数据预处理
针对业务上的一些统计数据，可以将数据按日统计好在放入一张中间表中，之后将相关的定时任务脚本部署好，每日进行统计数据的增量更新。此举会明显加快系统的相应时间。增量更新与全量更新相结合更能保证数据的可靠性。

>读写分离，定期同步。
主库写从库读，定期同步数据。


## 后记

这应该是我所知道的关于SQL查询优化的所有技能了。mysql是有查询优化器帮忙优化，但是正如卓哥（店达架构师）说的一样：一定要有写高性能的sql语句的意识。

再补充几点：
1、不要想把所有的事情都交给mysql交给SQL。SQL语句整个执行是一个黑盒。我们没有办法去debug看看具体的数据流。一个较为恰当的做法就是粗加工基础数据，再把这些数据用程序来进行相关的计算。这样即便是有问题，我们也可以轻松的定位问题。
2、个人心得：SQL书写的准确性不是难在语法，而是业务上的。我们需要对用到的每张表有所认知。知道每张表的细粒度。也就是这样，我们才会对各种连接查询之后的那个虚拟的表的数据结构有一个清楚的认识。也就是这样才能保证我们的数据是正确的。

后期还会更新一些东西，今晚要休息了。
回想起在店达的时光。再次感谢店达的小伙伴，鞠躬。
转载请注明出处。

